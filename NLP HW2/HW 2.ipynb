{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d0bb8f-1490-4fa9-86fd-09249fde3f16",
   "metadata": {},
   "source": [
    "# Homework 2: Train A Skip-Gram model with negative sampling without using Word2Vec library.\n",
    "\n",
    "## Author: Ou, Dongwen; Student ID: 15220212202866\n",
    "\n",
    "### The HW2 is divided into 6 parts:\n",
    "\n",
    "* 1. Data preprocessing(Tokenization)\n",
    "  2. Skip-Gram pair data preparation\n",
    "  3. Negative Sampling data generation\n",
    "  4. Model definition using Pytorch with negative sampling MLE loss function\n",
    "  5. Using SGD to train the model and some hyperparameter settings\n",
    "  6. Check the results(output embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5796587c-3737-4391-afad-27529d367494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['it', 'is', 'a', 'sunny', 'day.', 'anna', 'wakes', 'up', 'early.', 'she', 'eats', 'her', 'breakfast.', 'she', 'drinks', 'a', 'glass', 'of', 'milk.', 'then', 'she', 'puts', 'on', 'her', 'shoes.', 'anna', 'is', 'happy', 'today.', 'anna', 'goes', 'to', 'the', 'park', 'with', 'her', 'dog.', 'her', 'dog', 'is', 'small.', 'her', 'dog', 'is', 'brown.', 'his', 'name', 'is', 'max.', 'max', 'is', 'a', 'happy', 'dog.', 'max', 'likes', 'to', 'run.', 'in', 'the', 'park,', 'there', 'are', 'many', 'trees.', 'the', 'trees', 'are', 'tall.', 'the', 'leaves', 'are', 'green.', 'birds', 'sing', 'in', 'the', 'trees.', 'the', 'sun', 'shines.', 'the', 'sky', 'is', 'blue.', 'it', 'is', 'a', 'nice', 'day.', 'anna', 'sees', 'her', 'friend.', 'her', 'friend', 'is', 'tom.', 'tom', 'has', 'a', 'bike.', 'the', 'bike', 'is', 'red.', 'tom', 'rides', 'his', 'bike', 'fast.', 'anna', 'waves', 'to', 'tom.', 'tom', 'waves', 'back.', 'anna', 'and', 'tom', 'sit', 'on', 'a', 'bench.', 'they', 'eat', 'snacks.', 'anna', 'has', 'an', 'apple.', 'tom', 'has', 'a', 'sandwich.', 'max', 'eats', 'a', 'dog', 'biscuit.', 'max', 'drinks', 'some', 'water.', 'a', 'ball', 'rolls', 'by.', 'max', 'sees', 'the', 'ball.', 'max', 'runs', 'after', 'the', 'ball.', 'max', 'loves', 'to', 'play.', 'max', 'is', 'very', 'fast.', 'he', 'brings', 'the', 'ball', 'back', 'to', 'anna.', 'anna', 'throws', 'the', 'ball', 'again.', 'max', 'runs', 'again.', 'more', 'children', 'come', 'to', 'the', 'park.', 'they', 'play', 'on', 'the', 'swings.', 'they', 'slide', 'down', 'the', 'slide.', 'they', 'laugh', 'and', 'have', 'fun.', 'the', 'park', 'is', 'full', 'of', 'joy.', 'tom', 'and', 'anna', 'play', 'tag.', 'they', 'run', 'and', 'laugh.', 'max', 'runs', 'with', 'them.', 'max', 'barks.', 'everyone', 'is', 'happy.', 'after', 'a', 'while,', 'they', 'sit', 'under', 'a', 'tree.', 'they', 'feel', 'the', 'wind.', 'the', 'wind', 'is', 'cool.', 'the', 'grass', 'is', 'soft.', 'anna', 'lies', 'down.', 'she', 'looks', 'at', 'the', 'clouds.', 'the', 'clouds', 'move', 'slowly.', 'anna', 'sees', 'a', 'bird', 'in', 'the', 'sky.', 'the', 'bird', 'is', 'white.', 'it', 'flies', 'high.', 'tom', 'sees', 'a', 'squirrel.', 'the', 'squirrel', 'runs', 'up', 'a', 'tree.', 'max', 'watches', 'the', 'squirrel.', 'max', 'does', 'not', 'bark.', 'soon', 'it', 'is', 'noon.', 'the', 'sun', 'is', 'hot.', 'anna', 'is', 'hungry.', 'tom', 'is', 'hungry', 'too.', 'they', 'say', 'goodbye.', 'tom', 'rides', 'his', 'bike', 'home.', 'anna', 'walks', 'home', 'with', 'max.', 'at', 'home,', 'anna', 'eats', 'lunch.', 'she', 'eats', 'rice', 'and', 'chicken.', 'she', 'drinks', 'juice.', 'max', 'eats', 'his', 'dog', 'food.', 'then', 'they', 'rest.', 'in', 'the', 'afternoon,', 'anna', 'reads', 'a', 'book.', 'the', 'book', 'is', 'about', 'animals.', 'she', 'likes', 'cats.', 'she', 'likes', 'lions.', 'she', 'reads', 'about', 'monkeys.', 'max', 'sleeps', 'on', 'the', 'floor.', 'later,', 'anna', 'draws', 'a', 'picture.', 'she', 'draws', 'the', 'park.', 'she', 'draws', 'trees', 'and', 'flowers.', 'she', 'draws', 'tom', 'and', 'max.', 'she', 'uses', 'many', 'colors.', 'she', 'is', 'proud', 'of', 'her', 'picture.', 'max', 'wakes', 'up.', 'he', 'wants', 'to', 'go', 'out.', 'anna', 'takes', 'him', 'to', 'the', 'yard.', 'max', 'runs', 'in', 'the', 'yard.', 'anna', 'waters', 'the', 'plants.', 'the', 'flowers', 'are', 'red,', 'yellow,', 'and', 'blue.', 'the', 'sun', 'starts', 'to', 'go', 'down.', 'the', 'sky', 'turns', 'orange.', 'anna', 'and', 'max', 'go', 'inside.', 'anna', 'helps', 'her', 'mom', 'cook', 'dinner.', 'they', 'make', 'soup', 'and', 'noodles.', 'it', 'smells', 'good.', 'at', 'dinner,', 'the', 'family', 'sits', 'together.', 'they', 'talk', 'about', 'their', 'day.', 'anna', 'tells', 'them', 'about', 'the', 'park.', 'she', 'tells', 'them', 'about', 'tom.', 'she', 'shows', 'them', 'her', 'drawing.', 'everyone', 'smiles.', 'after', 'dinner,', 'anna', 'takes', 'a', 'bath.', 'she', 'brushes', 'her', 'teeth.', 'she', 'puts', 'on', 'her', 'pajamas.', 'max', 'lies', 'on', 'his', 'bed.', 'anna', 'reads', 'one', 'more', 'book.', 'then', 'she', 'turns', 'off', 'the', 'light.', 'max', 'jumps', 'onto', 'her', 'bed.', 'anna', 'hugs', 'max.', 'she', 'says,', '“good', 'night,', 'max.”', 'max', 'closes', 'his', 'eyes.', 'outside,', 'the', 'stars', 'shine.', 'the', 'moon', 'is', 'bright.', 'it', 'is', 'a', 'quiet', 'night.', 'anna', 'and', 'max', 'are', 'asleep.', 'it', 'was', 'a', 'good', 'day.', 'lucy', 'has', 'a', 'cat.', 'the', 'cat’s', 'name', 'is', 'coco.', 'coco', 'is', 'white', 'and', 'soft.', 'she', 'likes', 'to', 'play.', 'one', 'day,', 'lucy', 'throws', 'a', 'small', 'ball.', 'coco', 'runs', 'after', 'the', 'ball.', 'coco', 'jumps.', 'coco', 'catches', 'the', 'ball.', 'lucy', 'claps', 'her', 'hands.', 'lucy', 'throws', 'the', 'ball', 'again.', 'coco', 'runs', 'fast.', 'she', 'hits', 'the', 'ball', 'with', 'her', 'paw.', 'the', 'ball', 'rolls', 'under', 'the', 'table.', 'coco', 'looks', 'under', 'the', 'table.', 'she', 'sees', 'the', 'ball.', 'she', 'pushes', 'it', 'out.', 'she', 'meows.', 'lucy', 'laughs.', 'coco', 'jumps', 'on', 'the', 'couch.', 'she', 'plays', 'with', 'the', 'ball.', 'the', 'ball', 'falls', 'to', 'the', 'floor.', 'coco', 'follows', 'the', 'ball.', 'she', 'never', 'gets', 'tired.', 'in', 'the', 'evening,', 'coco', 'sleeps', 'on', 'lucy’s', 'bed.', 'she', 'hugs', 'the', 'ball.', 'lucy', 'hugs', 'coco.', 'they', 'are', 'best', 'friends.', 'tom', 'has', 'a', 'bike.', 'his', 'bike', 'is', 'blue.', 'he', 'rides', 'it', 'every', 'day.', 'in', 'the', 'morning,', 'tom', 'rides', 'to', 'the', 'park.', 'the', 'sun', 'is', 'shining.', 'the', 'wind', 'is', 'cool.', 'tom', 'feels', 'happy.', 'he', 'sees', 'a', 'dog.', 'the', 'dog', 'barks.', 'tom', 'waves', 'at', 'the', 'dog.', 'the', 'dog', 'wags', 'its', 'tail.', 'tom', 'rides', 'faster.', 'he', 'goes', 'up', 'a', 'small', 'hill.', 'he', 'rides', 'down', 'fast.', 'he', 'laughs.', 'he', 'feels', 'the', 'wind', 'on', 'his', 'face.', 'he', 'sees', 'a', 'friend.', 'her', 'name', 'is', 'lily.', 'lily', 'has', 'a', 'red', 'bike.', 'they', 'ride', 'together.', 'they', 'talk', 'and', 'laugh.', 'after', 'a', 'while,', 'tom', 'feels', 'tired.', 'he', 'sits', 'under', 'a', 'tree.', 'lily', 'gives', 'him', 'water.', 'they', 'rest', 'together.', 'then', 'tom', 'rides', 'home.', 'his', 'mom', 'waves', 'at', 'him.', '“did', 'you', 'have', 'fun?”', 'she', 'asks.', 'tom', 'smiles.', '“yes,', 'i', 'did!”', 'there', 'is', 'a', 'pond', 'in', 'the', 'garden.', 'the', 'pond', 'has', 'many', 'fish.', 'the', 'fish', 'are', 'red,', 'yellow,', 'and', 'orange.', 'anna', 'comes', 'to', 'the', 'pond.', 'she', 'brings', 'fish', 'food.', 'she', 'throws', 'the', 'food', 'in', 'the', 'water.', 'the', 'fish', 'swim', 'to', 'the', 'top.', 'the', 'fish', 'eat', 'the', 'food.', 'they', 'open', 'their', 'mouths.', 'they', 'move', 'fast.', 'anna', 'watches', 'them.', 'she', 'is', 'happy.', 'a', 'big', 'fish', 'jumps.', 'splash!', 'water', 'falls', 'on', 'anna.', 'she', 'laughs.', 'a', 'frog', 'sits', 'on', 'a', 'rock.', 'the', 'frog', 'watches', 'the', 'fish.', 'it', 'makes', 'a', 'sound.', '“ribbit!', 'ribbit!”', 'anna', 'sees', 'a', 'turtle.', 'the', 'turtle', 'moves', 'slowly.', 'it', 'swims', 'in', 'the', 'pond.', 'anna', 'waves', 'at', 'the', 'turtle.', 'the', 'sun', 'is', 'warm.', 'the', 'water', 'is', 'clear.', 'anna', 'stays', 'by', 'the', 'pond.', 'she', 'loves', 'the', 'fish.', 'it', 'is', 'night.', 'the', 'moon', 'is', 'high.', 'stars', 'shine', 'in', 'the', 'sky.', 'ben', 'puts', 'on', 'his', 'pajamas.', 'he', 'brushes', 'his', 'teeth.', 'he', 'washes', 'his', 'face.', 'he', 'hugs', 'his', 'teddy', 'bear.', 'he', 'gets', 'into', 'bed.', 'the', 'bed', 'is', 'warm.', 'his', 'mom', 'reads', 'a', 'story.', 'the', 'story', 'is', 'about', 'a', 'bird.', 'ben', 'listens.', 'he', 'closes', 'his', 'eyes.', 'the', 'wind', 'blows', 'outside.', 'it', 'makes', 'a', 'soft', 'sound.', 'the', 'curtains', 'move.', 'the', 'room', 'is', 'quiet.', 'ben', 'dreams', 'of', 'flying.', 'he', 'flies', 'like', 'a', 'bird.', 'he', 'flies', 'over', 'trees', 'and', 'lakes.', 'in', 'the', 'morning,', 'the', 'sun', 'comes', 'up.', 'ben', 'opens', 'his', 'eyes.', 'he', 'feels', 'happy.', '“good', 'morning!”', 'he', 'says.']\n",
      "Vocab Size: 350 ['a', 'about', 'after', 'afternoon,', 'again.', 'an', 'and', 'animals.', 'anna', 'anna.', 'apple.', 'are', 'asks.', 'asleep.', 'at', 'back', 'back.', 'ball', 'ball.', 'bark.', 'barks.', 'bath.', 'bear.', 'bed', 'bed.', 'ben', 'bench.', 'best', 'big', 'bike', 'bike.', 'bird', 'bird.', 'birds', 'biscuit.', 'blows', 'blue.', 'book', 'book.', 'breakfast.', 'bright.', 'brings', 'brown.', 'brushes', 'by', 'by.', 'cat.', 'catches', 'cats.', 'cat’s', 'chicken.', 'children', 'claps', 'clear.', 'closes', 'clouds', 'clouds.', 'coco', 'coco.', 'colors.', 'come', 'comes', 'cook', 'cool.', 'couch.', 'curtains', 'day,', 'day.', 'did!”', 'dinner,', 'dinner.', 'does', 'dog', 'dog.', 'down', 'down.', 'drawing.', 'draws', 'dreams', 'drinks', 'early.', 'eat', 'eats', 'evening,', 'every', 'everyone', 'eyes.', 'face.', 'falls', 'family', 'fast.', 'faster.', 'feel', 'feels', 'fish', 'fish.', 'flies', 'floor.', 'flowers', 'flowers.', 'flying.', 'follows', 'food', 'food.', 'friend', 'friend.', 'friends.', 'frog', 'full', 'fun.', 'fun?”', 'garden.', 'gets', 'gives', 'glass', 'go', 'goes', 'good', 'good.', 'goodbye.', 'grass', 'green.', 'hands.', 'happy', 'happy.', 'has', 'have', 'he', 'helps', 'her', 'high.', 'hill.', 'him', 'him.', 'his', 'hits', 'home', 'home,', 'home.', 'hot.', 'hugs', 'hungry', 'hungry.', 'i', 'in', 'inside.', 'into', 'is', 'it', 'its', 'joy.', 'juice.', 'jumps', 'jumps.', 'lakes.', 'later,', 'laugh', 'laugh.', 'laughs.', 'leaves', 'lies', 'light.', 'like', 'likes', 'lily', 'lily.', 'lions.', 'listens.', 'looks', 'loves', 'lucy', 'lucy’s', 'lunch.', 'make', 'makes', 'many', 'max', 'max.', 'max.”', 'meows.', 'milk.', 'mom', 'monkeys.', 'moon', 'more', 'morning!”', 'morning,', 'mouths.', 'move', 'move.', 'moves', 'name', 'never', 'nice', 'night,', 'night.', 'noodles.', 'noon.', 'not', 'of', 'off', 'on', 'one', 'onto', 'open', 'opens', 'orange.', 'out.', 'outside,', 'outside.', 'over', 'pajamas.', 'park', 'park,', 'park.', 'paw.', 'picture.', 'plants.', 'play', 'play.', 'plays', 'pond', 'pond.', 'proud', 'pushes', 'puts', 'quiet', 'quiet.', 'reads', 'red', 'red,', 'red.', 'rest', 'rest.', 'ribbit!”', 'rice', 'ride', 'rides', 'rock.', 'rolls', 'room', 'run', 'run.', 'runs', 'sandwich.', 'say', 'says,', 'says.', 'sees', 'she', 'shine', 'shine.', 'shines.', 'shining.', 'shoes.', 'shows', 'sing', 'sit', 'sits', 'sky', 'sky.', 'sleeps', 'slide', 'slide.', 'slowly.', 'small', 'small.', 'smells', 'smiles.', 'snacks.', 'soft', 'soft.', 'some', 'soon', 'sound.', 'soup', 'splash!', 'squirrel', 'squirrel.', 'stars', 'starts', 'stays', 'story', 'story.', 'sun', 'sunny', 'swim', 'swims', 'swings.', 'table.', 'tag.', 'tail.', 'takes', 'talk', 'tall.', 'teddy', 'teeth.', 'tells', 'the', 'their', 'them', 'them.', 'then', 'there', 'they', 'throws', 'tired.', 'to', 'today.', 'together.', 'tom', 'tom.', 'too.', 'top.', 'tree.', 'trees', 'trees.', 'turns', 'turtle', 'turtle.', 'under', 'up', 'up.', 'uses', 'very', 'wags', 'wakes', 'walks', 'wants', 'warm.', 'was', 'washes', 'watches', 'water', 'water.', 'waters', 'waves', 'while,', 'white', 'white.', 'wind', 'wind.', 'with', 'yard.', 'yellow,', 'you', '“did', '“good', '“ribbit!', '“yes,']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "########################################\n",
    "# 1. 数据准备 & 预处理\n",
    "########################################\n",
    "\n",
    "with open(\"/Users/dongwenou/HW2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    mytext = f.read()\n",
    "\n",
    "\n",
    "# 将文本切分成词序列\n",
    "# 简单按空格拆分，并转小写\n",
    "# text: str\t说明参数 text 应该是一个 str（字符串）类型\n",
    "# -> List[str]\t表示函数的返回值是一个 List[str]，即“字符串列表”\n",
    "# List[str]\t表示列表中每个元素都是 str 类型（需要 from typing import List）\n",
    "def tokenize_corpus(text: str) -> List[str]:    \n",
    "    return text.lower().split()\n",
    "\n",
    "tokens = tokenize_corpus(mytext)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# 构建词表(去重) Vocabulary\n",
    "# 使用 collections.Counter 类来统计 tokens 中每个单词的出现次数。\n",
    "# word_counts 是一个类似字典的对象，记录了词频\n",
    "# 从 word_counts 中提取所有词（即字典的 key），并排序，生成词汇表。\n",
    "# vocab 是一个列表，里面是按字典序排序的词：\n",
    "word_counts = Counter(tokens)\n",
    "vocab = sorted(word_counts.keys())\n",
    "word2idx = {w: i for i, w in enumerate(vocab)} #0开始\n",
    "idx2word = {i: w for w, i in word2idx.items()} #items 返回key+value\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab Size:\", vocab_size, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0aca3cc6-8184-4b4d-85ea-7173ee7080a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skip-gram pairs: 10270\n",
      "Sample pairs (center_idx, outside_idx): [(148, 147), (148, 0), (148, 285), (148, 67), (148, 8), (147, 148), (147, 0), (147, 285), (147, 67), (147, 8)]\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 2. 生成 Skip-Gram 训练样本\n",
    "########################################\n",
    "\n",
    "# 在 skip-gram 模型中，我们对每个目标词 w_c (center word)\n",
    "# 从其上下文窗口内采样到 w_o (outside words) 来组成 (w_c, w_o)\n",
    "# 这里设置一个小的窗口大小 window_size=2 仅作示例\n",
    "\n",
    "def generate_skip_gram_pairs(tokens, window_size=5):\n",
    "    pairs = []\n",
    "    for i, center_word in enumerate(tokens):\n",
    "        center_idx = word2idx[center_word]\n",
    "        # 在中心词左右各 window_size 范围内找上下文词\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(tokens), i + window_size + 1)\n",
    "        for j in range(start, end):\n",
    "            if j != i:\n",
    "                outside_idx = word2idx[tokens[j]]\n",
    "                pairs.append((center_idx, outside_idx))\n",
    "    return pairs\n",
    "\n",
    "skip_gram_pairs = generate_skip_gram_pairs(tokens, window_size=5)\n",
    "print(\"Number of skip-gram pairs:\", len(skip_gram_pairs))\n",
    "print(\"Sample pairs (center_idx, outside_idx):\", skip_gram_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d15c746-279d-47cc-8429-57b7ae3cc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 3. 负采样函数\n",
    "########################################\n",
    "\n",
    "# 负采样: 对于每个 (center, outside) 正样本, 随机抽若干个负样本(词)\n",
    "# 这里使用词频分布近似, 并且简单示范: 负样本数量 negative_k 可调\n",
    "# 在实际应用中, 通常会构建一个更高效的采样表(如使用unigram^3/4等)\n",
    "\n",
    "word_freqs = np.array([word_counts[w] for w in vocab], dtype=np.float32)\n",
    "word_freqs = word_freqs / word_freqs.sum()  # 归一化为分布\n",
    "# 这里从分布的概率来抽取，比uniform抽全部高效些\n",
    "\n",
    "def negative_sampling(center_idx, outside_idx, negative_k=10):\n",
    "    # 返回 size=negative_k 的负样本索引列表\n",
    "    neg_samples = []\n",
    "    for _ in range(negative_k):\n",
    "        # 多次采样一个负样本, 与 outside_idx 不同即可\n",
    "        neg = np.random.choice(range(vocab_size), p=word_freqs)\n",
    "        while neg == outside_idx:\n",
    "            neg = np.random.choice(range(vocab_size), p=word_freqs) #抽到window内的词就进入这个无限循环until抽到不在的\n",
    "        neg_samples.append(neg)\n",
    "    return neg_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4901b-45cd-4c9d-aae3-1d48861f0fa4",
   "metadata": {},
   "source": [
    "所以负样本部分的 loss 是：\n",
    "$$\n",
    "\\text{neg loss} = -\\sum{j=1}^k \\log \\sigma\\left( -v_{w_c}^\\top v_{w_j^-} \\right)\n",
    "$$\n",
    "其中：\n",
    "* $v_{w_c}$：中心词的向量\n",
    "* $v_{w_j^-}$：第 j 个负样本词的向量\n",
    "* $\\sigma(\\cdot)$：sigmoid 函数\n",
    "\n",
    "bmm 是 batch matrix multiplication → 每个 batch 执行：\n",
    "$$\n",
    "\\text{neg\\_score}_i = \\text{neg\\_embed}_i \\cdot \\text{center}_i^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc81896a-6d57-47b5-a152-b1020a9a19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 4. 模型定义: SkipGramNegativeSamplingModel\n",
    "########################################\n",
    "\n",
    "class SkipGramNegativeSamplingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(SkipGramNegativeSamplingModel, self).__init__()\n",
    "        # 输入词向量表\n",
    "        self.input_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        # 输出词向量表 (可视为 \"context\" embeddings)\n",
    "        self.output_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # 初始化: \n",
    "        nn.init.uniform_(self.input_embeddings.weight, -0.5, 0.5) \n",
    "        nn.init.uniform_(self.output_embeddings.weight, -0.5, 0.5)\n",
    "        # 把 input_embeddings 这个矩阵里的所有数，全部设为 -0.5 到 +0.5 之间的随机数。\n",
    "\n",
    "    def forward(self, center_idx, outside_idx, neg_indices):\n",
    "        \"\"\"\n",
    "        center_idx: (batch_size,)  长度为 batch_size 的中心词索引\n",
    "        outside_idx: (batch_size,) 长度为 batch_size 的正样本(上下文)词索引\n",
    "        neg_indices: (batch_size, negative_k)  负样本词索引\n",
    "        \"\"\"\n",
    "        # 1) 取出中心词向量: shape=(batch_size, embed_dim)\n",
    "        center_embed = self.input_embeddings(center_idx)\n",
    "        \n",
    "        # 2) 取出正样本的输出向量: shape=(batch_size, embed_dim)\n",
    "        outside_embed = self.output_embeddings(outside_idx)\n",
    "        \n",
    "        # 3) 负样本的输出向量: shape=(batch_size, negative_k, embed_dim)\n",
    "        neg_embed = self.output_embeddings(neg_indices)\n",
    "        \n",
    "        # 计算正样本的 log-sigma(center_embed dot outside_embed)\n",
    "        # 先做逐元素乘法后再求和得到内积: shape=(batch_size,)\n",
    "        pos_score = torch.sum(center_embed * outside_embed, dim=1)\n",
    "        # log-sigma\n",
    "        pos_loss = -torch.log(torch.sigmoid(pos_score) + 1e-9)\n",
    "        \n",
    "        # 计算负样本的 log-sigma(- center_embed dot neg_embed)\n",
    "        # 先对 (batch_size, negative_k, embed_dim) 与 (batch_size,1,embed_dim) 做广播\n",
    "        center_embed_3d = center_embed.unsqueeze(1)  # 在指定位置插入维度 shape=(batch_size,1,embed_dim) \n",
    "        neg_score = torch.bmm(neg_embed, center_embed_3d.transpose(1,2)).squeeze() # 第1，2dim transpose：shape=(batch_size,embed_dim,1)\n",
    "        # batch matrix multiplication: (batch_size, negative_k, embed_dim) * (batch_size,embed_dim,1)\n",
    "        # squeeze() 会移除 tensor 中 所有 维度为 1 的“伪维度”\n",
    "        # neg_score shape = (batch_size, negative_k)\n",
    "        neg_loss = -torch.sum(torch.log(torch.sigmoid(-neg_score) + 1e-9), dim=1)\n",
    "        \n",
    "        # 总损失 = pos_loss + neg_loss, 取平均\n",
    "        loss = pos_loss + neg_loss\n",
    "        return loss.mean() #对batch取mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21e96851-d358-4de8-a4d5-f1a4a4a6ea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss = 9.4647\n",
      "Epoch 2/100, Loss = 9.2849\n",
      "Epoch 3/100, Loss = 9.1034\n",
      "Epoch 4/100, Loss = 9.0104\n",
      "Epoch 5/100, Loss = 8.8474\n",
      "Epoch 6/100, Loss = 8.7979\n",
      "Epoch 7/100, Loss = 8.7205\n",
      "Epoch 8/100, Loss = 8.6335\n",
      "Epoch 9/100, Loss = 8.5581\n",
      "Epoch 10/100, Loss = 8.4222\n",
      "Epoch 11/100, Loss = 8.4057\n",
      "Epoch 12/100, Loss = 8.3247\n",
      "Epoch 13/100, Loss = 8.2305\n",
      "Epoch 14/100, Loss = 8.1617\n",
      "Epoch 15/100, Loss = 8.1350\n",
      "Epoch 16/100, Loss = 8.0765\n",
      "Epoch 17/100, Loss = 8.0238\n",
      "Epoch 18/100, Loss = 7.9622\n",
      "Epoch 19/100, Loss = 7.9140\n",
      "Epoch 20/100, Loss = 7.9021\n",
      "Epoch 21/100, Loss = 7.8145\n",
      "Epoch 22/100, Loss = 7.7469\n",
      "Epoch 23/100, Loss = 7.6907\n",
      "Epoch 24/100, Loss = 7.6938\n",
      "Epoch 25/100, Loss = 7.6156\n",
      "Epoch 26/100, Loss = 7.5590\n",
      "Epoch 27/100, Loss = 7.5623\n",
      "Epoch 28/100, Loss = 7.5066\n",
      "Epoch 29/100, Loss = 7.4785\n",
      "Epoch 30/100, Loss = 7.4452\n",
      "Epoch 31/100, Loss = 7.3737\n",
      "Epoch 32/100, Loss = 7.3637\n",
      "Epoch 33/100, Loss = 7.2875\n",
      "Epoch 34/100, Loss = 7.2626\n",
      "Epoch 35/100, Loss = 7.2662\n",
      "Epoch 36/100, Loss = 7.1876\n",
      "Epoch 37/100, Loss = 7.1616\n",
      "Epoch 38/100, Loss = 7.1294\n",
      "Epoch 39/100, Loss = 7.0773\n",
      "Epoch 40/100, Loss = 7.0607\n",
      "Epoch 41/100, Loss = 7.0382\n",
      "Epoch 42/100, Loss = 6.9919\n",
      "Epoch 43/100, Loss = 6.9397\n",
      "Epoch 44/100, Loss = 6.9115\n",
      "Epoch 45/100, Loss = 6.9044\n",
      "Epoch 46/100, Loss = 6.8331\n",
      "Epoch 47/100, Loss = 6.8399\n",
      "Epoch 48/100, Loss = 6.7642\n",
      "Epoch 49/100, Loss = 6.7411\n",
      "Epoch 50/100, Loss = 6.7033\n",
      "Epoch 51/100, Loss = 6.6814\n",
      "Epoch 52/100, Loss = 6.6521\n",
      "Epoch 53/100, Loss = 6.6466\n",
      "Epoch 54/100, Loss = 6.6329\n",
      "Epoch 55/100, Loss = 6.5941\n",
      "Epoch 56/100, Loss = 6.5479\n",
      "Epoch 57/100, Loss = 6.5150\n",
      "Epoch 58/100, Loss = 6.4876\n",
      "Epoch 59/100, Loss = 6.4718\n",
      "Epoch 60/100, Loss = 6.4381\n",
      "Epoch 61/100, Loss = 6.4104\n",
      "Epoch 62/100, Loss = 6.3645\n",
      "Epoch 63/100, Loss = 6.3601\n",
      "Epoch 64/100, Loss = 6.3235\n",
      "Epoch 65/100, Loss = 6.2945\n",
      "Epoch 66/100, Loss = 6.2861\n",
      "Epoch 67/100, Loss = 6.2356\n",
      "Epoch 68/100, Loss = 6.2084\n",
      "Epoch 69/100, Loss = 6.2036\n",
      "Epoch 70/100, Loss = 6.1752\n",
      "Epoch 71/100, Loss = 6.1529\n",
      "Epoch 72/100, Loss = 6.1289\n",
      "Epoch 73/100, Loss = 6.1128\n",
      "Epoch 74/100, Loss = 6.0813\n",
      "Epoch 75/100, Loss = 6.0694\n",
      "Epoch 76/100, Loss = 6.0274\n",
      "Epoch 77/100, Loss = 5.9974\n",
      "Epoch 78/100, Loss = 5.9893\n",
      "Epoch 79/100, Loss = 5.9515\n",
      "Epoch 80/100, Loss = 5.9416\n",
      "Epoch 81/100, Loss = 5.9214\n",
      "Epoch 82/100, Loss = 5.8999\n",
      "Epoch 83/100, Loss = 5.8944\n",
      "Epoch 84/100, Loss = 5.8478\n",
      "Epoch 85/100, Loss = 5.8271\n",
      "Epoch 86/100, Loss = 5.8207\n",
      "Epoch 87/100, Loss = 5.8077\n",
      "Epoch 88/100, Loss = 5.7814\n",
      "Epoch 89/100, Loss = 5.7441\n",
      "Epoch 90/100, Loss = 5.7336\n",
      "Epoch 91/100, Loss = 5.7386\n",
      "Epoch 92/100, Loss = 5.6952\n",
      "Epoch 93/100, Loss = 5.6741\n",
      "Epoch 94/100, Loss = 5.6667\n",
      "Epoch 95/100, Loss = 5.6652\n",
      "Epoch 96/100, Loss = 5.6249\n",
      "Epoch 97/100, Loss = 5.6089\n",
      "Epoch 98/100, Loss = 5.6059\n",
      "Epoch 99/100, Loss = 5.5483\n",
      "Epoch 100/100, Loss = 5.5727\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 5. 训练循环\n",
    "########################################\n",
    "\n",
    "embed_dim = 250       # 词向量维度(示例用小值)\n",
    "batch_size = 128      # 小批量示例\n",
    "negative_k = 10      # 每个正样本对应的负样本数\n",
    "num_epochs = 100    # 训练轮数\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = SkipGramNegativeSamplingModel(vocab_size, embed_dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "skip_gram_dataset = skip_gram_pairs  # (center, outside)\n",
    "\n",
    "# 简单的随机打乱\n",
    "random.shuffle(skip_gram_dataset)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    # 小批量迭代\n",
    "    for i in range(0, len(skip_gram_dataset), batch_size): # 按batch_size前进\n",
    "        batch = skip_gram_dataset[i:i+batch_size] # 会自动截断如果最后个batch会超出len一些\n",
    "        center_idxs = []\n",
    "        outside_idxs = []\n",
    "        neg_idxs = []\n",
    "        \n",
    "        for (c_idx, o_idx) in batch: # 对batch中的每一对pair迭代\n",
    "            center_idxs.append(c_idx)\n",
    "            outside_idxs.append(o_idx)\n",
    "            # 采样负样本\n",
    "            neg_samples = negative_sampling(c_idx, o_idx, negative_k)\n",
    "            neg_idxs.append(neg_samples)\n",
    "        \n",
    "        # 转成张量\n",
    "        center_idxs = torch.LongTensor(center_idxs)\n",
    "        outside_idxs = torch.LongTensor(outside_idxs)\n",
    "        neg_idxs = torch.LongTensor(neg_idxs)\n",
    "        \n",
    "        optimizer.zero_grad() #清除旧梯度\n",
    "        loss = model(center_idxs, outside_idxs, neg_idxs)\n",
    "        loss.backward()\n",
    "        optimizer.step() # 用梯度更新模型参数\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / (len(skip_gram_dataset)//batch_size + 1)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss = {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "faf5d0bb-2fa4-48d7-8521-c16c4b42bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample word embeddings:\n",
      "a [ 0.12500648 -0.24841152  0.11608797 -0.43430963  0.1264059  -0.16214198\n",
      "  0.03620679 -0.400952   -0.2495335  -0.09767942  0.27385178  0.16979522\n",
      " -0.24268594  0.34422678 -0.37057665  0.17289004  0.0265836  -0.07478195\n",
      " -0.193217   -0.07839001  0.02435297  0.34743235  0.07988136  0.18423913\n",
      " -0.43022582  0.05761949 -0.32126608 -0.11741664  0.30754644 -0.02126164\n",
      " -0.5402174   0.0211986   0.22809786 -0.00406621 -0.48834205  0.22167626\n",
      "  0.5146758  -0.36203519 -0.12522145 -0.07781565  0.6099289  -0.43707013\n",
      "  0.43391475 -0.5692686   0.05781138 -0.20382635 -0.23156177 -0.09643977\n",
      " -0.12604962  0.56816494  0.10666183 -0.35973626  0.30222863 -0.43313092\n",
      "  0.0391289  -0.29154727  0.10652043 -0.09386367  0.21546584  0.19213304\n",
      "  0.1583878  -0.00696401  0.10511545  0.27266312 -0.57757187 -0.19456562\n",
      "  0.59627664  0.43019283  0.07762172  0.1327848  -0.03823346  0.04018035\n",
      " -0.3422041  -0.04510762 -0.14435397  0.30756602  0.14534819  0.21165152\n",
      " -0.43293792  0.4421645   0.09952111  0.25218344  0.49456668 -0.25798023\n",
      " -0.19345933 -0.12444716  0.17265621  0.13813439 -0.21214518 -0.37531143\n",
      "  0.02488498  0.2702082  -0.03230321  0.39409256  0.3599795   0.10721821\n",
      "  0.14992535  0.22764353  0.17432861  0.02759258  0.17312153 -0.279672\n",
      " -0.29807222 -0.12693574  0.03728882  0.32257405  0.4197125   0.38076344\n",
      "  0.24567567  0.46987122  0.24247494  0.19617489 -0.1930766  -0.2739062\n",
      " -0.26353702 -0.32175106  0.20853868  0.42474204  0.133521   -0.03628891\n",
      " -0.29528543 -0.3463794  -0.16114886 -0.15622108 -0.21876332 -0.3513066\n",
      "  0.2149407   0.22885512  0.08163724 -0.15750875  0.08540807 -0.35928524\n",
      "  0.21934861  0.0955552  -0.27188894 -0.05369486 -0.2510285   0.04364115\n",
      "  0.03435768  0.6111332  -0.46090126  0.12022162  0.34505937 -0.06799766\n",
      " -0.511509   -0.00968187 -0.28709638 -0.07643645 -0.1238682   0.29544848\n",
      "  0.13235089  0.32501358 -0.1040441  -0.5072307   0.31667674 -0.00283097\n",
      " -0.350023    0.43898794  0.17991774  0.3342668   0.44876972 -0.00311563\n",
      " -0.23359632  0.23132363  0.53539807 -0.06125925 -0.27056867  0.1675609\n",
      " -0.38782266 -0.32233578  0.30051696  0.45125747  0.18242249  0.51836365\n",
      "  0.19106108 -0.12212867 -0.25771648  0.14394814 -0.35962296  0.1698676\n",
      " -0.12957965  0.46685958 -0.0898381   0.32685977 -0.17113124 -0.20194928\n",
      "  0.11291332 -0.04072831 -0.03544232 -0.28936568  0.14659134  0.474556\n",
      "  0.31075534 -0.15394202  0.20891818  0.21979642 -0.12965685  0.3232224\n",
      "  0.20281047 -0.4652665  -0.23121661  0.32605183 -0.32468948 -0.31218022\n",
      "  0.36025354 -0.17803138  0.34441677  0.06223684  0.3373171  -0.4491685\n",
      "  0.57566446  0.27254346  0.19331719 -0.5639014   0.43557864  0.39568046\n",
      "  0.24130103 -0.03539133 -0.24493034  0.02490887  0.075166    0.05399777\n",
      "  0.38867575 -0.2246219  -0.01966955 -0.4876593   0.11116437  0.40919197\n",
      " -0.2901782   0.14312126 -0.13200025  0.24054444  0.39098102  0.07316858\n",
      " -0.05407356 -0.20550577  0.26021484  0.21575896 -0.19053033  0.02208282\n",
      " -0.41822076 -0.13141103 -0.37341273  0.48778307 -0.3698305   0.15320534\n",
      "  0.3970993  -0.305085    0.3069907   0.42891887]\n",
      "\n",
      "about [-0.15812168  0.29666197 -0.3451333   0.22315302 -0.21706088 -0.17885716\n",
      "  0.32469434 -0.11647817  0.06746622  0.43340525 -0.43106467 -0.03200122\n",
      "  0.16898775  0.20778738 -0.35919428 -0.02751945 -0.21338113  0.4063355\n",
      "  0.2527636  -0.06440408  0.320786   -0.391707   -0.25174907 -0.0166794\n",
      "  0.0143119  -0.00942351  0.11182514 -0.02453126  0.43742734  0.06697886\n",
      " -0.17654353 -0.22404113  0.41707817 -0.12186024  0.4170796   0.07053503\n",
      " -0.2504536  -0.3511261   0.03011174 -0.07034743  0.09912544  0.06573783\n",
      "  0.12676995 -0.35154983  0.5003513   0.06028788 -0.34888312  0.27439338\n",
      "  0.18076177 -0.14900884  0.36864653  0.0626188   0.21172994 -0.06260125\n",
      " -0.23324147 -0.2970636  -0.4439916  -0.09831633  0.0186207  -0.14395039\n",
      "  0.16576755 -0.50364876  0.21860015  0.06675316 -0.17627105 -0.38367984\n",
      " -0.16603653  0.02900111  0.04860822 -0.23469727 -0.33918396  0.03863778\n",
      "  0.03291385 -0.10140357  0.2267058   0.31000262 -0.25964862  0.05297301\n",
      "  0.0140093   0.07203098  0.34349626 -0.42396215  0.06610365 -0.12261516\n",
      "  0.15545982 -0.28972054 -0.19171545 -0.1632772   0.36826777 -0.2400543\n",
      "  0.31451815  0.26418978  0.10402462 -0.21255592  0.46491095 -0.17611988\n",
      "  0.16367316 -0.151569    0.24718253 -0.40720433  0.23945317  0.48030183\n",
      "  0.31632978  0.28663176 -0.28808144 -0.21080482  0.08256233  0.10118561\n",
      "  0.32135308  0.30987003  0.11313505 -0.2058353  -0.10752264  0.32526502\n",
      " -0.43692774 -0.37514967 -0.3182374  -0.30282277 -0.5224637  -0.01304255\n",
      "  0.35095626  0.29365918 -0.19730361 -0.04108138  0.01125874  0.06760959\n",
      "  0.2954923  -0.04589939  0.16023634 -0.28757107 -0.07457723  0.1878359\n",
      "  0.01925364 -0.00797712  0.19673742  0.37505913 -0.21304934 -0.3959669\n",
      "  0.11041733 -0.25578132  0.37882283 -0.23430982 -0.3488959  -0.18276484\n",
      " -0.19405574  0.26504534  0.09624645  0.27471837 -0.45493597 -0.20205587\n",
      "  0.18190038 -0.0448376   0.03671144  0.2995614   0.08119391  0.49151626\n",
      " -0.03481688  0.5316908  -0.18048772 -0.01378718 -0.39943206 -0.3191598\n",
      " -0.45196554  0.14151484 -0.29019228  0.3697669  -0.01249787 -0.07609496\n",
      "  0.13990493 -0.23762639  0.5245191   0.18602726 -0.02593011  0.32268232\n",
      "  0.21177024  0.17288174 -0.01706151 -0.22432698  0.2850495   0.18380208\n",
      "  0.19415918 -0.31718412 -0.4054272   0.20925017 -0.08410677 -0.34640017\n",
      " -0.20884563 -0.056313    0.10600055 -0.2090931  -0.25012165 -0.19905114\n",
      " -0.38949656  0.4032951   0.20607248 -0.10777837 -0.39709452  0.2038698\n",
      "  0.20343553 -0.07047494  0.3817582   0.25550544  0.24249943 -0.10608551\n",
      " -0.15985897 -0.2786503   0.4658647  -0.25544697 -0.06721799 -0.44496122\n",
      "  0.21774702  0.16759756  0.2363562   0.06512413 -0.28977987  0.29244417\n",
      "  0.28701264  0.2673328  -0.06618385 -0.36147672 -0.0117933   0.14205371\n",
      " -0.3276634  -0.13589656 -0.09456066  0.24539441 -0.11866381  0.1632637\n",
      "  0.03842638 -0.39549962 -0.0271922   0.05010191 -0.21410395  0.30445737\n",
      " -0.2518221  -0.1703302  -0.2805319   0.40117964  0.32266405 -0.17975064\n",
      "  0.03972895 -0.0545462  -0.1998437  -0.4178647   0.16004375 -0.13660459\n",
      "  0.48934862 -0.4414671  -0.1392637  -0.03046893]\n",
      "\n",
      "after [-3.40052933e-01 -1.26720920e-01  2.74180889e-01  4.55067217e-01\n",
      " -1.55941561e-01  2.50632465e-01  1.34022444e-01 -3.20649326e-01\n",
      "  2.37598926e-01  1.45018220e-01 -1.86159700e-01 -2.81736910e-01\n",
      " -2.74070382e-01 -3.00675392e-01  2.36806348e-01 -3.61839920e-01\n",
      "  3.08247596e-01  1.97633564e-01  5.12932777e-01 -4.45708811e-01\n",
      " -3.69153142e-01  1.18819540e-02  3.82963240e-01 -3.12978268e-01\n",
      "  3.44904870e-01 -2.77794510e-01  1.81138664e-01 -1.87483549e-01\n",
      " -3.89467716e-01 -2.63012975e-01  6.38430044e-02  2.94112474e-01\n",
      "  3.82654279e-01 -5.36484480e-01 -1.49370119e-01 -1.06940605e-01\n",
      " -9.97899622e-02 -1.75424457e-01  3.30867022e-01 -2.14289292e-03\n",
      " -2.39174422e-02 -4.68353689e-01  5.41078568e-01 -1.73433006e-01\n",
      "  2.79714257e-01 -3.85348409e-01  4.42269146e-01  6.54813945e-02\n",
      " -1.29100651e-01 -6.23646751e-03  4.15960588e-02  2.13370070e-01\n",
      " -2.65310168e-01  3.42362970e-01 -2.02524617e-01  3.65010351e-01\n",
      " -2.74059266e-01 -1.48804799e-01  1.82264879e-01  1.61803201e-01\n",
      "  1.44614100e-01 -1.92637756e-01 -2.01754477e-02 -2.07156584e-01\n",
      "  4.62301746e-02  4.27244902e-01 -3.79516333e-01 -3.22154582e-01\n",
      " -4.51431751e-01  4.35059555e-02  2.11282045e-01  1.22473635e-01\n",
      "  4.47378099e-01 -3.28440398e-01  1.29308671e-01  2.60456264e-01\n",
      "  1.89964786e-01 -1.98728099e-01  3.36541124e-02  4.49095964e-01\n",
      " -4.14498687e-01  4.47912633e-01  3.97787362e-01 -1.51857823e-01\n",
      " -1.52081087e-01 -4.37277138e-01 -4.33619395e-02 -3.48652363e-01\n",
      " -8.28546006e-03 -3.78649235e-01  5.61237112e-02 -9.53850374e-02\n",
      " -2.62504071e-01 -5.93882054e-02 -5.40381819e-02  4.73215789e-01\n",
      "  1.48593793e-02 -2.66366422e-01  2.54811019e-01  4.02928114e-01\n",
      "  3.04964762e-02  3.19303304e-01 -4.17447537e-01  2.42239767e-04\n",
      " -2.24836078e-02  5.44705510e-01 -1.77144319e-01 -3.23425889e-01\n",
      "  5.06472230e-01 -2.26007089e-01  2.49535605e-01 -4.39906240e-01\n",
      "  3.38130504e-01  3.11952353e-01 -4.62423623e-01  6.51569515e-02\n",
      " -3.32015485e-01  4.85646009e-01  3.30772877e-01 -2.90212691e-01\n",
      "  2.94770002e-01  5.09357080e-02  8.19279701e-02 -5.10742605e-01\n",
      "  2.46507138e-01 -9.76864621e-02 -2.35752359e-01  1.10934965e-01\n",
      " -3.94065440e-01  3.34537715e-01 -3.60181004e-01 -2.61861324e-01\n",
      "  1.74222440e-01 -3.18805695e-01 -4.08113122e-01  2.94757336e-01\n",
      " -3.30732137e-01  3.15835834e-01  3.46071154e-01 -3.44269753e-01\n",
      " -4.74238575e-01  3.45531315e-01 -1.96577191e-01  9.88619626e-02\n",
      " -4.40412492e-01 -3.06709647e-01  3.23314816e-01 -3.28330606e-01\n",
      " -2.93800205e-01 -3.45300019e-01  4.05450732e-01  8.47409591e-02\n",
      "  4.02500570e-01 -2.36114845e-01 -6.93615973e-02  1.43199429e-01\n",
      "  1.35389939e-01 -4.29476023e-01 -9.26139280e-02 -1.54973716e-01\n",
      "  8.34029093e-02 -2.84246922e-01 -5.05732775e-01 -1.47711439e-02\n",
      "  1.54311374e-01  1.80518299e-01 -1.90846562e-01 -5.28814077e-01\n",
      " -4.44711536e-01  4.23488557e-01  3.86054248e-01 -2.92186499e-01\n",
      " -2.04970777e-01  5.13098717e-01  1.11015931e-01  3.39261480e-02\n",
      " -4.69250500e-01  1.18635789e-01  3.19515258e-01  1.11192476e-03\n",
      "  7.34883472e-02  1.55005569e-03  3.96688044e-01  5.93448505e-02\n",
      "  3.18511158e-01  5.06133199e-01 -5.39586954e-02  3.06811005e-01\n",
      " -4.89921987e-01 -1.76014021e-01 -3.52257192e-01  4.41851586e-01\n",
      " -3.79133046e-01 -2.40035146e-01 -4.05888945e-01 -4.84085143e-01\n",
      " -4.82066005e-01  5.16600549e-01  3.56710881e-01 -4.12170112e-01\n",
      "  2.93008089e-01 -2.32001409e-01 -2.81458169e-01  1.54725775e-01\n",
      " -5.98513484e-02 -4.31659877e-01  5.01416028e-01  4.27131921e-01\n",
      " -4.03543800e-01  6.70514032e-02 -3.89218569e-01  1.11598901e-01\n",
      "  2.97610126e-02 -4.13129702e-02  6.46773353e-02 -8.96372050e-02\n",
      "  3.13041866e-01 -2.69075722e-01 -2.73786873e-01  1.46866754e-01\n",
      "  2.27139145e-01  3.95490140e-01 -2.81882554e-01  7.39133433e-02\n",
      "  2.15638310e-01  2.80623555e-01  7.44905183e-03 -7.83666670e-02\n",
      "  4.27264087e-02  2.95967907e-01 -3.98176283e-01 -3.07340831e-01\n",
      " -2.40608662e-01  4.63890463e-01  3.80663931e-01 -2.22589850e-01\n",
      " -7.79553428e-02  2.33737659e-02  5.13969779e-01 -2.66726464e-01\n",
      "  3.04242074e-01 -1.64881214e-01 -1.88117206e-01 -3.85008365e-01\n",
      " -3.56335729e-01 -1.05828352e-01  3.24065983e-01 -3.05046350e-01\n",
      "  4.90484003e-04  9.29298326e-02]\n",
      "\n",
      "afternoon, [ 0.10349192  0.16658324  0.16388127 -0.13603874  0.2993869   0.22066015\n",
      " -0.06033972  0.44499144  0.42368433 -0.09113873  0.36326197 -0.337506\n",
      "  0.2901545  -0.09938824  0.02031164 -0.36661294  0.289969   -0.05749001\n",
      "  0.32750276 -0.3413102  -0.02309917 -0.27134383 -0.45191315 -0.4153337\n",
      "  0.21829298 -0.1402084  -0.1968692   0.31817225 -0.44267046  0.22880644\n",
      " -0.43733236 -0.19611876  0.31361195  0.46667007 -0.19499968  0.3096672\n",
      "  0.36993304  0.43847466 -0.29447988  0.08614451 -0.39919817  0.4462872\n",
      " -0.40031543  0.38438597 -0.26944208  0.46452454  0.13812867  0.3557343\n",
      " -0.39104548  0.37583032  0.43921453  0.3801021  -0.1051245   0.08216293\n",
      " -0.04306565 -0.30503404 -0.24731205 -0.4893157  -0.27220044 -0.11122605\n",
      "  0.42544562 -0.24352431  0.34088713 -0.5165957  -0.47865716 -0.4189582\n",
      "  0.26530883  0.06648415  0.1769851  -0.3724002  -0.389849   -0.14897017\n",
      " -0.32555524  0.40343878  0.10520498  0.3445802   0.03737046 -0.03325902\n",
      " -0.4848494  -0.20273708 -0.42134565 -0.07393958  0.4229283  -0.05046076\n",
      " -0.47221908  0.09248389 -0.43150595 -0.42786583  0.1351675   0.04774222\n",
      " -0.14298494  0.3424678   0.26297534  0.11669843  0.06296149 -0.30102092\n",
      "  0.25444892 -0.01755622  0.35494447 -0.44744903 -0.06097    -0.07278236\n",
      "  0.0348089  -0.24206974  0.4174388   0.11353788  0.30281064  0.01252748\n",
      "  0.01619561 -0.3362242   0.43946356  0.13501248 -0.31007808 -0.23032072\n",
      "  0.03667889  0.29603067  0.3958191   0.34285423 -0.24362546  0.31118444\n",
      " -0.290537    0.45037606  0.22109282  0.39799172 -0.31109574 -0.31230983\n",
      "  0.01516471  0.19199732 -0.3910155  -0.17784703  0.46732044 -0.06809469\n",
      " -0.32792488  0.45726478  0.20894685 -0.2737751  -0.23243594  0.1454955\n",
      "  0.273015    0.20090993 -0.187755   -0.01579942 -0.07954234 -0.23076397\n",
      "  0.41506734  0.27517188  0.02352306 -0.08735631  0.28976077  0.10061795\n",
      "  0.4890736  -0.1218203   0.22921303  0.12159289 -0.42471042 -0.11704729\n",
      "  0.1112508  -0.40116096 -0.00561018  0.1364035   0.44164693  0.01770192\n",
      " -0.4282006  -0.2373549   0.05971322  0.44427484  0.41479802 -0.2931893\n",
      "  0.42448604 -0.2816299  -0.46420735 -0.4526994  -0.12972865  0.40943378\n",
      " -0.13755287 -0.05590111  0.11574205  0.3855461   0.06219837 -0.31968883\n",
      "  0.33814088  0.1167172  -0.3830912   0.44440755 -0.19760972  0.18155025\n",
      "  0.3737033   0.43446136 -0.44115278 -0.36650226  0.2412799   0.24963917\n",
      "  0.06137992 -0.13489963  0.34077388  0.33160448  0.05173646 -0.2211058\n",
      "  0.15334634  0.35967126  0.34025916 -0.43376532  0.2669863   0.28105435\n",
      " -0.00953535 -0.04611152  0.38582474 -0.06231106  0.41022125  0.04271379\n",
      " -0.00255545  0.01298472  0.35397542  0.336212    0.3536551   0.08137353\n",
      " -0.08659251 -0.47668362  0.46001443 -0.10020354 -0.06716343  0.3841596\n",
      " -0.37891054 -0.2532013   0.11621405 -0.4679856   0.30050358  0.36821097\n",
      " -0.35579443 -0.0855692  -0.01755243  0.2543302  -0.2591015  -0.06737092\n",
      " -0.0987263  -0.41284406  0.2824624   0.23321615 -0.04446555 -0.28499025\n",
      " -0.5068276  -0.20710279 -0.04653626 -0.13054296 -0.00100033 -0.03008261\n",
      " -0.02146676  0.4849451   0.17429076 -0.4148681 ]\n",
      "\n",
      "again. [ 0.4332386  -0.44879368  0.18122776 -0.4204326   0.2248368  -0.37863177\n",
      "  0.26497632  0.3080984   0.06301839  0.18137367 -0.47063097 -0.27480665\n",
      "  0.31275082 -0.26474282 -0.25745413 -0.38560164 -0.05760349  0.35183308\n",
      "  0.33727548 -0.18394057 -0.31359655 -0.43327072  0.36094224  0.3150772\n",
      " -0.2870464  -0.24862482 -0.4258748  -0.4408974   0.362751    0.10639665\n",
      " -0.3692842  -0.02709134  0.00792827 -0.03254905 -0.14763829 -0.43384868\n",
      " -0.23474146 -0.16665876  0.3874154  -0.10693225  0.4011136  -0.4504007\n",
      " -0.4272223  -0.370137   -0.1933449   0.27995872  0.10245311 -0.05848956\n",
      " -0.20598705  0.27006578 -0.44198313 -0.20563315  0.00972892 -0.3093892\n",
      " -0.10930642  0.18031389  0.03516389  0.36049643 -0.11629674  0.39716572\n",
      "  0.3142181  -0.10859019  0.30664018 -0.40776083 -0.1904704   0.06595975\n",
      " -0.47475144 -0.3317188  -0.47186327 -0.1152036   0.15195565 -0.2366995\n",
      " -0.19441284 -0.37579557  0.4091363  -0.26662984 -0.24151355 -0.35175422\n",
      " -0.3259148  -0.07483228  0.40075862  0.14596675  0.3451639  -0.2831922\n",
      "  0.37542453 -0.02527298 -0.22463846  0.18389428 -0.5045966  -0.3921702\n",
      " -0.39514652 -0.40862817  0.30095693 -0.3397624   0.42454612 -0.20982519\n",
      "  0.24776898  0.17537199 -0.40953252 -0.06145407 -0.20807663 -0.33127257\n",
      "  0.38159356 -0.35457838 -0.33109227 -0.4441201  -0.36362326 -0.03613566\n",
      "  0.01900331 -0.05771959  0.14700705 -0.09220576  0.3544591   0.27466777\n",
      " -0.166485   -0.18070379  0.07688947 -0.15433379 -0.02531785  0.22050956\n",
      " -0.32016772 -0.4386635  -0.42237964 -0.03790405  0.4597029   0.07649218\n",
      " -0.18839714 -0.27911726  0.17205998  0.29156262  0.18344712  0.02753812\n",
      "  0.23774388  0.5251549   0.37463126 -0.21784337 -0.07008716 -0.06621142\n",
      "  0.4041394  -0.4043245  -0.1523255  -0.3384559   0.16015223  0.01611385\n",
      " -0.49459413  0.42689398  0.27477458  0.15843593  0.4081487  -0.45558926\n",
      "  0.26184842 -0.2120862   0.097201   -0.28120637  0.13941269  0.21238059\n",
      " -0.21416579  0.3651377  -0.20026413  0.13880111 -0.4882567  -0.48600307\n",
      " -0.12024141 -0.1759026   0.45430747 -0.22243045  0.41385782 -0.06521579\n",
      " -0.45904922 -0.11683916 -0.3356498  -0.2707817   0.30631924 -0.23795924\n",
      "  0.00555119 -0.03763768 -0.32032567  0.23638786  0.12918091  0.12464324\n",
      "  0.36408365  0.40066066 -0.15388988 -0.49559668  0.28304744  0.03183288\n",
      "  0.07996263  0.31382868 -0.05811487 -0.32627556  0.12719949 -0.06141236\n",
      " -0.46525162 -0.10806821  0.43070248  0.3789525  -0.45102322 -0.16194081\n",
      "  0.32882196 -0.38768116 -0.31006336  0.02250968 -0.02752443 -0.13493742\n",
      " -0.23055764 -0.01926005  0.04638222  0.09321019  0.04877919 -0.12693453\n",
      " -0.3783841   0.10956772  0.36078596  0.08128637  0.17279433  0.39292502\n",
      "  0.09694188  0.3596912   0.16575746 -0.06428511 -0.09722248 -0.3119991\n",
      "  0.15697314 -0.2072493  -0.22571889 -0.04726003  0.28737196  0.25835928\n",
      " -0.21133779  0.41929287  0.40460947 -0.07154421  0.13561925 -0.27681312\n",
      "  0.09234665  0.4656392  -0.07113716  0.13998865  0.26191285 -0.0744473\n",
      " -0.52968866 -0.24515511  0.3850291  -0.4063234   0.44968733  0.2963827\n",
      " -0.3298806  -0.14869793 -0.28936452  0.19403312]\n",
      "\n",
      "an [-0.2895784   0.2981878  -0.10770629  0.09993557 -0.2422812  -0.09319015\n",
      "  0.04702562 -0.11731146  0.43470156  0.38769072  0.12580936  0.18255109\n",
      "  0.2112899   0.46542388 -0.01734157  0.0203586   0.04032106 -0.21144047\n",
      "  0.19538155 -0.10706347  0.48694795  0.38186988  0.04544859  0.0415057\n",
      " -0.40675956 -0.2199348   0.1091842   0.21550718  0.27312604  0.2400401\n",
      " -0.26595187 -0.04956989 -0.15169846  0.38530913  0.22412114 -0.18112504\n",
      "  0.12760907  0.41391847 -0.22973377  0.46279216 -0.2674151   0.19149525\n",
      "  0.42947304 -0.37376273  0.21281622  0.38503513 -0.35327289 -0.11689824\n",
      "  0.17747271 -0.23519671  0.18323551 -0.14583044 -0.2812305  -0.42635238\n",
      "  0.37263113 -0.04918137 -0.2536581  -0.40663487 -0.2786977  -0.42132524\n",
      "  0.34790373  0.46467853 -0.27425155 -0.27664477 -0.24214181  0.4864382\n",
      " -0.52973163  0.15248576 -0.46646312  0.32197732 -0.1420439   0.09145857\n",
      "  0.01773674  0.35772467  0.26942685 -0.28062013  0.0583      0.13104412\n",
      " -0.15329774  0.08849186  0.14365716 -0.45583084  0.2628361  -0.44705576\n",
      " -0.24847268  0.02434355  0.4201538   0.2213232   0.3087644   0.2728478\n",
      "  0.08001183  0.18665162  0.4655388  -0.08776049 -0.35038048 -0.12917458\n",
      "  0.11219298 -0.22857712 -0.29577598  0.4225171  -0.14958917  0.45227855\n",
      "  0.2706897   0.2611464   0.13688958  0.3963536   0.35517284  0.23140265\n",
      "  0.3923572  -0.2368957   0.31199068 -0.10302149  0.03444481 -0.14190616\n",
      " -0.17284364  0.3723326  -0.22514799  0.13416877  0.43054223 -0.4612708\n",
      "  0.02563152 -0.06998222  0.2016461   0.42472827 -0.41638982 -0.32201335\n",
      "  0.15216321 -0.11690733 -0.32388803  0.27024797 -0.2457586  -0.16836402\n",
      "  0.20819333  0.30959412 -0.171192   -0.28412047  0.41743225  0.42263028\n",
      "  0.29520625 -0.3903403   0.46928486  0.2881099  -0.0586357  -0.05054682\n",
      "  0.41665956 -0.0366249   0.0069638   0.2737261   0.07735997  0.30375463\n",
      " -0.16562684 -0.0406815  -0.4563982  -0.00270541 -0.2706752  -0.39204633\n",
      " -0.08407848  0.11396595  0.43602356 -0.16425747 -0.40712136 -0.22744656\n",
      "  0.08159535  0.19151624  0.21863438  0.3920208  -0.43029523  0.43688142\n",
      " -0.46874586 -0.4150685   0.25125626 -0.3794767  -0.14749317 -0.0531638\n",
      " -0.03364482 -0.0977624   0.481397    0.13199653 -0.32463136  0.20501003\n",
      "  0.2306458   0.21874292  0.4467151   0.3715079  -0.1927592   0.30877507\n",
      "  0.14449038  0.31797418  0.26906466 -0.10571988  0.44524193 -0.04294265\n",
      "  0.21044464 -0.31205168  0.3860923   0.4219564  -0.40041628 -0.02314743\n",
      " -0.23556054 -0.3376446  -0.3491646   0.03220998  0.18644306  0.02436272\n",
      " -0.38108286  0.03876612  0.3747872  -0.15573707  0.20129734 -0.00882409\n",
      "  0.48956248 -0.32566768 -0.2908738   0.3963628  -0.27074027  0.39968154\n",
      "  0.10739087 -0.28700477  0.36550486 -0.1332002   0.07728294 -0.08548249\n",
      "  0.27413398  0.23803726 -0.43284288 -0.4663514  -0.04717123  0.3096559\n",
      " -0.18690957  0.42766324  0.36829445 -0.16162513 -0.37061065  0.21924563\n",
      " -0.21039917 -0.46059224  0.3102402  -0.12735166  0.1376692   0.2832177\n",
      " -0.47708192  0.2049783   0.1343038  -0.3848405   0.2820695   0.14621325\n",
      "  0.11182328  0.11359591  0.02714407  0.5057534 ]\n",
      "\n",
      "and [-0.16341314 -0.27834383 -0.44269887 -0.23222353 -0.22234166  0.52068627\n",
      "  0.41363373  0.30406716  0.2002723  -0.06319894 -0.08249255  0.06006086\n",
      " -0.14627063  0.3947419   0.0722781  -0.11341315  0.19977352 -0.25000072\n",
      " -0.01636599 -0.17692341 -0.29397035 -0.42515936 -0.01461495 -0.5944839\n",
      " -0.00627008  0.03372738  0.0572215   0.24799718  0.19316131  0.2498592\n",
      "  0.20870574 -0.43516377 -0.0603355  -0.45851374  0.11479231 -0.49081326\n",
      "  0.16125455  0.0975994  -0.5033572   0.48047566  0.4566942  -0.0886922\n",
      "  0.1042227   0.24239881  0.0699707  -0.19646044 -0.34319237  0.30459422\n",
      " -0.09235951  0.07182639 -0.3360618  -0.42390633  0.34795135 -0.28983152\n",
      " -0.0023604  -0.02953287 -0.44517922  0.1068802   0.0941077   0.36644164\n",
      "  0.15413383 -0.28693032  0.03289355 -0.44641525  0.07211942  0.15448722\n",
      " -0.12478247 -0.3343679  -0.0623834   0.34420067  0.12627724  0.22101662\n",
      "  0.17753084 -0.38896078 -0.31005028  0.05126502 -0.03335928  0.01997184\n",
      " -0.61643755 -0.12169649  0.4558961   0.28230846 -0.43221414 -0.11866336\n",
      " -0.07093255 -0.21244515 -0.3838714  -0.545394   -0.05530378  0.10497948\n",
      "  0.237432   -0.21635431 -0.42999163 -0.39721158  0.10107794 -0.21450509\n",
      " -0.11686591 -0.05261838 -0.3406723  -0.27385098 -0.12106451  0.31458125\n",
      " -0.21229674 -0.11655213  0.1375469   0.39199415  0.14440756  0.4968746\n",
      "  0.10109795  0.21786883  0.32292864 -0.04383184  0.3728077   0.2460768\n",
      "  0.25595507 -0.3554919  -0.46885678  0.47917363 -0.0471337  -0.15384513\n",
      "  0.42136428  0.12561826 -0.05779959  0.04200245  0.4129436  -0.3917579\n",
      " -0.25431332  0.47825706  0.06860276 -0.25344327  0.13507979  0.14871891\n",
      " -0.07736424 -0.01475331  0.08956955  0.17356758 -0.22159293  0.23167446\n",
      " -0.21934251 -0.03506573  0.22487573 -0.11587954 -0.264815   -0.16234621\n",
      " -0.3110128   0.2157397   0.21783221 -0.29431233  0.15817149  0.19773689\n",
      "  0.31899443 -0.21537904 -0.3968081  -0.01519369  0.25312224  0.03976474\n",
      " -0.02739628  0.25044712  0.10531613  0.26436964  0.32969838  0.45324036\n",
      "  0.20232165 -0.1641711   0.48297477 -0.40188208  0.3714537  -0.12406848\n",
      " -0.32894498  0.1113802   0.05306602  0.11013784  0.00360264  0.24843958\n",
      "  0.38924998  0.2556845   0.36229178 -0.23264706  0.15673968 -0.2628022\n",
      " -0.20355254 -0.37027097  0.36687866 -0.42862576  0.2499609   0.5260763\n",
      " -0.41356945 -0.15043302 -0.06169046  0.27458054  0.3318097   0.4170085\n",
      " -0.3560924   0.36162364 -0.3567679  -0.27605844  0.01578781  0.03371318\n",
      "  0.57083774  0.09785926 -0.04281607  0.43592644 -0.19883916 -0.33907697\n",
      "  0.30593666 -0.5260049  -0.34645626  0.10519071  0.14978603 -0.16466238\n",
      "  0.0620506  -0.33637494 -0.05951575  0.21882097 -0.17751461 -0.2603114\n",
      "  0.09062514  0.11169272  0.31969464  0.33926672 -0.28625205 -0.11953367\n",
      " -0.2562329   0.00823462 -0.44000763 -0.15235794 -0.1283838  -0.28198922\n",
      "  0.40429762  0.30307788 -0.30665728 -0.05864672  0.44943696  0.17635334\n",
      " -0.21431574  0.24233873 -0.33576053 -0.04166108  0.39612463  0.10930866\n",
      " -0.2949848   0.5196789   0.09634992 -0.27827376  0.20703432  0.297573\n",
      " -0.23989682 -0.32468683  0.06545667  0.16829133]\n",
      "\n",
      "animals. [-0.44128767 -0.46684647 -0.36873555 -0.36712888  0.32026407  0.13204099\n",
      " -0.42449105  0.00200607  0.31800994  0.26022094 -0.44186127 -0.14562888\n",
      "  0.27849597 -0.2641606   0.2652901  -0.19565237 -0.27432933  0.2658556\n",
      "  0.06496932  0.4690545   0.37298262 -0.47135356 -0.32504076 -0.3948897\n",
      " -0.32366616  0.49067003  0.03631948 -0.18729807 -0.3920309   0.48173583\n",
      " -0.26391464 -0.14671955  0.24112411  0.3370642  -0.35646144  0.10971005\n",
      " -0.02259952 -0.04116286 -0.20916882 -0.27188528  0.32673854 -0.50347376\n",
      "  0.23783979  0.44720832 -0.04515032 -0.07140867  0.05537606  0.20144998\n",
      "  0.45188725  0.15356337  0.20441785 -0.2464525   0.22805062  0.18341474\n",
      " -0.29110947  0.22747278  0.165851    0.41294104  0.09889724 -0.43585634\n",
      " -0.19562007 -0.4130447  -0.41169566 -0.3136573   0.1318405  -0.3333897\n",
      "  0.17815635  0.0211969  -0.04159929 -0.5238886  -0.07823806  0.42896548\n",
      " -0.32281855 -0.45211703  0.44493133  0.4337896   0.02808123 -0.270498\n",
      " -0.04414593 -0.29144892  0.04737407 -0.18923104 -0.4796655   0.28465536\n",
      "  0.3672112   0.25551388  0.03882789 -0.46364245 -0.37788716 -0.40269408\n",
      " -0.24881722  0.00174293 -0.3067375   0.31234926 -0.33436748  0.22426002\n",
      " -0.25769687 -0.15449877  0.45246994 -0.08319204 -0.0124231  -0.24857739\n",
      " -0.08601462 -0.17562258  0.01733857  0.21858816 -0.2504505   0.33530354\n",
      "  0.08148029  0.08658548  0.22657432  0.32960552  0.2083602  -0.36808738\n",
      "  0.05848176 -0.1508499  -0.29311046 -0.01299498 -0.02095272  0.39144847\n",
      "  0.2541167  -0.16733567 -0.10287637  0.02329737  0.41243345 -0.4595981\n",
      " -0.16873534  0.31364343  0.25354066  0.3093312   0.16470216  0.15424491\n",
      " -0.07852292 -0.4221535  -0.00136163 -0.1632223  -0.34599334 -0.18552145\n",
      " -0.06528258 -0.37749162  0.27276817  0.2959163   0.42501652 -0.41633508\n",
      " -0.32115284  0.42392194 -0.32546845 -0.15581922  0.27067712 -0.37369743\n",
      "  0.34960178  0.01631566 -0.34750906 -0.14244449 -0.05707281 -0.20018153\n",
      "  0.39122787  0.36986935  0.01580647  0.38181683  0.34524044  0.17525896\n",
      " -0.37968215  0.50044554  0.13589394  0.15949732  0.12005572 -0.26816812\n",
      " -0.34661263  0.43520314 -0.4497015   0.29470468  0.33558023 -0.10149638\n",
      "  0.12556098  0.31727427  0.32195142 -0.20560531 -0.28919616 -0.10362982\n",
      " -0.30935556  0.21432196  0.17841144 -0.43883634 -0.20888804 -0.20045419\n",
      "  0.13675633  0.05626233  0.42802495 -0.37012807 -0.12232038  0.4306468\n",
      " -0.08147159 -0.15336175  0.1772777  -0.4666511   0.003188    0.1575346\n",
      " -0.37027654 -0.5095945   0.14342742  0.01006663 -0.24815284 -0.32782647\n",
      "  0.35891107  0.4316988   0.06712757  0.47374234 -0.0732862   0.45762393\n",
      "  0.3756651  -0.3970443  -0.00511397 -0.02509732  0.05107423 -0.2037368\n",
      " -0.34141108 -0.29987136  0.3327098  -0.20549119  0.34472665  0.28708428\n",
      " -0.16416624 -0.06822431  0.29800227 -0.36264685  0.31526488 -0.01329734\n",
      " -0.05932119 -0.43787184 -0.29853055 -0.3019431  -0.34756485  0.41309592\n",
      "  0.10347812 -0.02020603 -0.04773138  0.0284063   0.23098558  0.4158774\n",
      "  0.3870476  -0.3083385  -0.43719038  0.361812   -0.04433116 -0.22472498\n",
      " -0.42209792 -0.05729635  0.38570032 -0.07892375]\n",
      "\n",
      "anna [-2.44461782e-02  1.78073660e-01  1.43075243e-01 -1.37721434e-01\n",
      " -4.13975388e-01  1.23714991e-01  4.35206860e-01  1.54701024e-01\n",
      " -1.26716003e-01  2.51174662e-02 -1.95415497e-01 -2.45734900e-02\n",
      "  2.79662311e-01  3.70793074e-01 -3.40832025e-01  2.80724168e-01\n",
      " -2.25380719e-01  3.18063885e-01  2.45140836e-01 -1.15140580e-01\n",
      "  2.13402897e-01 -3.50356191e-01  2.14130625e-01  1.47364348e-01\n",
      "  1.07812613e-01 -1.58199623e-01 -2.08972752e-01 -9.45458561e-02\n",
      " -1.96771502e-01  5.16742229e-01 -2.74964839e-01  2.01093540e-01\n",
      " -2.05314174e-01 -2.11795151e-01  2.98059225e-01  1.92561865e-01\n",
      " -2.66142845e-01 -2.36828357e-01 -5.34538329e-01 -5.72633743e-03\n",
      "  5.86277485e-01 -3.08463842e-01 -5.45075648e-02 -4.35601367e-04\n",
      "  2.20795527e-01  1.65482312e-01  2.83800513e-01  1.69143841e-01\n",
      " -2.65311509e-01  1.58996135e-01 -2.79404849e-01  3.59632701e-01\n",
      " -1.94320083e-01 -4.05728191e-01  1.96139738e-02 -6.28646195e-01\n",
      " -7.95460716e-02  2.99849719e-01 -1.54950038e-01 -6.55176044e-02\n",
      " -6.00836575e-02 -1.89727023e-01  8.31067213e-04 -4.92221177e-01\n",
      " -2.14576021e-01 -2.68284947e-01  1.14512905e-01 -1.92721710e-01\n",
      " -1.30250931e-01  2.52046078e-01  2.30823189e-01  2.56038308e-01\n",
      "  2.94623435e-01  3.92028809e-01 -1.43923938e-01  5.27607799e-01\n",
      " -3.00793320e-01  4.12851781e-01 -3.15534413e-01  4.52212900e-01\n",
      " -6.16053157e-02  3.89169484e-01  1.04816057e-01 -2.16671273e-01\n",
      " -2.29798362e-01  1.59495875e-01  1.76569223e-01  1.54469330e-02\n",
      "  5.84300309e-02 -3.82560372e-01  3.21759552e-01 -1.26971960e-01\n",
      "  2.80580223e-02 -4.60464448e-01  2.96836823e-01  1.05321206e-01\n",
      " -1.76836729e-01 -9.58095118e-02  1.91743210e-01  2.71758437e-01\n",
      "  2.48110801e-01 -2.57916927e-01  2.29610056e-01  5.14171682e-02\n",
      "  3.16529661e-01  4.74682987e-01  2.33650759e-01  6.42898142e-01\n",
      "  1.59566358e-01 -3.26809347e-01 -3.13188463e-01 -3.22318673e-02\n",
      "  1.99386194e-01 -4.13753897e-01 -1.24199517e-01 -2.79988497e-01\n",
      "  1.12260126e-01  1.31325245e-01 -1.38740227e-01  3.44918638e-01\n",
      " -4.96713459e-01 -4.13470685e-01 -2.14120954e-01 -2.87779737e-02\n",
      "  2.45039657e-01 -1.84858620e-01  2.79715478e-01  3.68493259e-01\n",
      " -3.21860045e-01 -7.21045658e-02 -1.51634380e-01  1.09866440e-01\n",
      " -1.94888949e-01  5.04884779e-01  3.58745128e-01  3.57266814e-02\n",
      " -5.98527351e-03  1.21168360e-01 -4.14903253e-01  5.19113541e-01\n",
      " -2.40112960e-01  3.04558665e-01  2.28068054e-01  2.55989760e-01\n",
      " -4.72488821e-01 -3.11658114e-01  1.26216784e-01  1.34411335e-01\n",
      " -3.33092481e-01 -2.58135367e-02  1.06876642e-01  4.35376316e-01\n",
      " -1.36080697e-01 -2.42866948e-01  1.26556426e-01  4.34785634e-01\n",
      "  2.52755642e-01 -7.26186410e-02  3.81164938e-01 -1.09616056e-01\n",
      "  2.16827601e-01  2.45002434e-02  1.88464463e-01  2.80246377e-01\n",
      " -2.02015471e-02  1.42917514e-01  2.38005877e-01 -3.00111592e-01\n",
      " -1.40845701e-01  4.12306994e-01 -6.97288737e-02  3.57876688e-01\n",
      "  1.36234671e-01  4.48338389e-01 -1.96953312e-01 -5.08658230e-01\n",
      " -4.58597690e-02  4.06252518e-02  1.98065087e-01 -2.80435294e-01\n",
      " -4.45226699e-01 -6.42321482e-02 -3.48921686e-01  3.32557470e-01\n",
      "  9.67182443e-02  2.99089909e-01 -3.79199237e-01 -4.40711141e-01\n",
      "  9.79535505e-02 -1.27814591e-01  1.55970864e-02  5.97185194e-01\n",
      "  5.48646748e-02  1.91910148e-01  4.66457188e-01 -1.54438272e-01\n",
      " -1.85249731e-01 -2.15973958e-01  1.06778674e-01  3.38908851e-01\n",
      "  1.14176750e-01  1.61299169e-01  6.60543889e-02  1.26925603e-01\n",
      "  2.95038521e-01 -2.94662297e-01  7.50605091e-02 -2.14001611e-01\n",
      "  3.52001697e-01  5.47545515e-02  1.38443457e-02  1.75947845e-01\n",
      "  3.56782824e-01  2.31555849e-01 -8.56942832e-02 -1.10117709e-02\n",
      " -1.48298189e-01 -1.16893463e-01 -4.03150827e-01  3.24564159e-01\n",
      " -1.90038612e-04 -8.81505534e-02 -1.63806275e-01  3.48439455e-01\n",
      " -4.78528589e-02 -5.73578715e-01 -1.68274492e-01 -2.41032168e-01\n",
      "  1.16921440e-01  5.25232434e-01 -2.90518194e-01  3.28762203e-01\n",
      "  6.00120187e-01  4.14553016e-01 -1.86162546e-01  2.18652457e-01\n",
      " -3.08539242e-01  9.85057876e-02 -1.73736259e-01  1.25672624e-01\n",
      " -1.09841246e-02  2.56118961e-02  1.24565497e-01  7.50032812e-02\n",
      " -1.11295216e-01  3.53018522e-01  3.05060714e-01  1.64216295e-01\n",
      "  2.13753298e-01  2.56527871e-01]\n",
      "\n",
      "anna. [ 0.29743305  0.39903018 -0.1422116   0.07686923  0.02243348  0.4642599\n",
      " -0.15336527  0.17347683  0.27070886  0.05718682  0.42783928 -0.42631492\n",
      "  0.20307516 -0.3701886  -0.38438165  0.28203562 -0.2648362   0.07415227\n",
      " -0.14517626 -0.01962136 -0.20468888 -0.41409174 -0.10679523 -0.00673528\n",
      " -0.31935316  0.45701778 -0.1090802   0.20214142  0.01868724  0.2736585\n",
      "  0.15517466 -0.07328609 -0.4509161  -0.44141743  0.11585219 -0.3828584\n",
      "  0.10579572 -0.38489103 -0.18152797 -0.14543623  0.35249755  0.36795974\n",
      " -0.44094074 -0.1432931   0.47447565 -0.02972887 -0.13712041 -0.08887132\n",
      "  0.03372371 -0.21107315  0.50079006  0.0233162  -0.17982821 -0.19502144\n",
      "  0.46051565  0.36657128  0.30163634 -0.13895516 -0.29109976  0.11440226\n",
      "  0.2942348   0.1960011   0.4115408   0.32418638  0.14906648  0.12457242\n",
      "  0.24370798 -0.42012376 -0.31438348  0.02897209  0.31671685 -0.05370049\n",
      "  0.03065181  0.22597802  0.09082443  0.4577737   0.09052504 -0.18511117\n",
      "  0.4802713  -0.24144161 -0.33861363 -0.07946023  0.09901814 -0.2959961\n",
      " -0.09616582 -0.27084026 -0.07253119 -0.23496534  0.0791958  -0.10776932\n",
      "  0.19993106  0.30336052 -0.12917069 -0.15839422  0.11547402  0.0459676\n",
      " -0.18606055  0.25428173  0.43434036  0.3481509  -0.3547771  -0.32103142\n",
      "  0.5132136   0.3422005  -0.19386959  0.03731872  0.4964968   0.53785706\n",
      " -0.37282297 -0.03688681  0.02831025 -0.10806289 -0.16595261 -0.12275277\n",
      " -0.0485091   0.49007145  0.04303544  0.30734414 -0.0075989  -0.05411772\n",
      "  0.36101052 -0.20425688  0.47421736 -0.31894466  0.07410134 -0.41818154\n",
      " -0.05127425  0.19586028  0.12533693  0.07290376  0.44905573  0.18014596\n",
      "  0.44312695  0.00662378  0.3850472  -0.19755103  0.02634358 -0.02483116\n",
      " -0.20952809 -0.00214936 -0.5093233   0.4129502  -0.52390677  0.23000573\n",
      " -0.02343619  0.4993519  -0.02960337 -0.37844926 -0.2365133  -0.10190219\n",
      " -0.30174804  0.33725396  0.389314   -0.01750387 -0.11514423  0.28413793\n",
      "  0.3933866   0.22128862 -0.33399326 -0.14738278 -0.34101    -0.15830192\n",
      " -0.19792485 -0.36763027 -0.21286839  0.29547688 -0.38654178  0.1303105\n",
      "  0.430066   -0.35979307 -0.259079   -0.25194034  0.151224   -0.4029662\n",
      " -0.06598228 -0.2362914   0.3112399   0.28507736 -0.11271775 -0.43701467\n",
      "  0.065997   -0.05960212  0.07917956 -0.23021835  0.1885372   0.18991733\n",
      "  0.36277494 -0.2746425   0.30126786 -0.315633    0.21465133  0.21342517\n",
      " -0.03994    -0.3267304   0.49331066 -0.10164668  0.02591838  0.51909524\n",
      "  0.03254275 -0.1788107  -0.35059613 -0.45185724  0.14037359 -0.46632725\n",
      " -0.35122022 -0.20229983  0.29841274 -0.2120541   0.49431774  0.10502092\n",
      "  0.32971528 -0.42758155 -0.10434613  0.17195845 -0.19253728 -0.48615164\n",
      "  0.12850466 -0.14721122  0.27375996 -0.11006298  0.1921253   0.35738438\n",
      " -0.15469253 -0.07100065 -0.3632698   0.4199767   0.04124767  0.4110133\n",
      "  0.01699368 -0.35363287  0.00250694  0.42626438 -0.35343674  0.5115154\n",
      "  0.40985632  0.32256615  0.35363695  0.24623443  0.1602588  -0.01763048\n",
      " -0.36524767  0.13208467  0.40866184  0.25701255 -0.3983526  -0.05417041\n",
      " -0.31246004  0.33645946 -0.48470876  0.5143233 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 6. 结果查看: Embeddings\n",
    "########################################\n",
    "\n",
    "# 最终的词向量(输入embedding)\n",
    "word_embeddings = model.input_embeddings.weight.data.cpu().numpy()\n",
    "\n",
    "print(\"\\nSample word embeddings:\")\n",
    "for i, w in enumerate(vocab[:10]):\n",
    "    print(w, word_embeddings[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a8d69-67f5-41bb-9dcc-44f632d17aef",
   "metadata": {},
   "source": [
    "* From the above output, we can see the loss function value is dropping gradually with our SGD technique.\n",
    "\n",
    "* However, it may not be very good, as the text I used to train the model is just several thousand words. In order to improve the model performance, more words and topics should be covered.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a11504b-1d70-4dee-9c9d-4d25de2efa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "range(0, 5)\n",
      "range(5, 10)\n",
      "range(10, 15)\n",
      "range(15, 20)\n",
      "range(20, 23)\n"
     ]
    }
   ],
   "source": [
    "array_b = range(0,23)\n",
    "print(array_b[5])\n",
    "for i in range(0, 23, 5):\n",
    "    a = array_b[i:i+5]\n",
    "    print(a)\n",
    "# python list would automatically cut the out-lier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac357f54-161c-4ef5-bce3-203560894c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
